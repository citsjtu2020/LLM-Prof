#!/usr/bin/env python3
"""
SGLangæ¡†æ¶ LLM-Prof æ•°æ®æ•´åˆè„šæœ¬
æ•´åˆSGLangæ¡†æ¶æ¡ˆä¾‹çš„SEAã€MEAã€OEAä¸‰å±‚æ•°æ®ï¼Œç”¨äºæ¨ªå‘å¯¹æ¯”åˆ†æ
æ•°æ®æºï¼š
1. SEA+MEA: oea_analysis_for_sglang/cases_after_sea_with_mea.csv
2. OEA: cases_after_sea/{GPU_TYPE}/{CASE_NAME}/oea_summary_*.json
"""

import json
import os
import pandas as pd
import re
from pathlib import Path
from typing import Dict, List, Any, Optional
from glob import glob

class SGLangDataIntegrator:
    def __init__(self, base_dir: str = "."):
        self.base_dir = Path(base_dir)
        self.hardware_specs = {}
        self.load_hardware_specs()
        
    def load_hardware_specs(self):
        """åŠ è½½ç¡¬ä»¶è§„æ ¼æ•°æ®"""
        hardware_specs_raw = {
            "NVIDIA_A10": {"mem_bandwidth": 600 * (1024**3), "FP16": 125e12, "INT8": 250e12, "memsize": 24 * (1024**3)},
            "NVIDIA_L20": {"mem_bandwidth": 864 * (1024**3), "FP16": 119.5e12, "INT8": 239e12, "memsize": 48 * (1024**3)},
            "NVIDIA_H20_SXM5_96GB": {"mem_bandwidth": 4022 * (1024**3), "FP16": 148e12, "INT8": 296e12, "memsize": 96 * (1024**3)},
            "NVIDIA_H20_SXM5_141GB": {"mem_bandwidth": 4800 * (1024**3), "FP16": 148e12, "INT8": 296e12, "memsize": 141 * (1024**3)},
            "NVIDIA_A100_SXM4_80GB": {"mem_bandwidth": 2039 * (1024**3), "FP16": 312e12, "INT8": 624e12, "memsize": 80 * (1024**3)},
            "NVIDIA_A800_SXM4_80GB": {"mem_bandwidth": 2039 * (1024**3), "FP16": 312e12, "INT8": 624e12, "memsize": 80 * (1024**3)},
            "NVIDIA_H800": {"mem_bandwidth": 3350 * (1024**3), "FP16": 989e12, "INT8": 1979e12, "memsize": 80 * (1024**3)},
            "NVIDIA_H100": {"mem_bandwidth": 3350 * (1024**3), "FP16": 989e12, "INT8": 1979e12, "memsize": 80 * (1024**3)},
            "NVIDIA_H200": {"mem_bandwidth": 4800 * (1024**3), "FP16": 989e12, "INT8": 1979e12, "memsize": 141 * (1024**3)},
            "NVIDIA_B200": {"mem_bandwidth": 8000 * (1024**3), "FP16": 2250e12, "INT8": 4500e12, "memsize": 192 * (1024**3)},
            "AMD_MI308X": {"mem_bandwidth": 4000 * (1024**3), "FP16": 115e12, "INT8": 230e12, "memsize": 192 * (1024**3)},
        }
        
        # è½¬æ¢ä¸ºTFLOPså’ŒGB/så•ä½
        for gpu_name, specs in hardware_specs_raw.items():
            self.hardware_specs[gpu_name] = {
                "mem_bandwidth_gbps": specs["mem_bandwidth"] / (1024**3),
                "fp16_tflops": specs["FP16"] / 1e12,
                "int8_tops": specs["INT8"] / 1e12,
                "memory_size_gb": specs["memsize"] / (1024**3)
            }
    
    def load_sea_mea_data(self) -> pd.DataFrame:
        """åŠ è½½SEA+MEAæ•°æ®"""
        # ä¿®æ”¹è·¯å¾„ï¼šå…ˆå°è¯• oea_analysis_for_sglang ç›®å½•
        csv_file = self.base_dir / "oea_analysis_for_sglang" / "cases_after_sea_with_mea.csv"
        
        # å¦‚æœä¸å­˜åœ¨ï¼Œå°è¯•å½“å‰ç›®å½•
        if not csv_file.exists():
            csv_file = self.base_dir / "cases_after_sea_with_mea.csv"
        
        if not csv_file.exists():
            print(f"âŒ æœªæ‰¾åˆ°SEA+MEAæ•°æ®æ–‡ä»¶: {csv_file}")
            return pd.DataFrame()
        
        print(f"ğŸ“Š åŠ è½½SEA+MEAæ•°æ®: {csv_file}")
        df = pd.read_csv(csv_file)
        print(f"   æ‰¾åˆ° {len(df)} ä¸ªæ¡ˆä¾‹çš„SEA+MEAæ•°æ®")
        
        return df
    
    def find_oea_summary_files(self) -> Dict[str, Path]:
        """æŸ¥æ‰¾æ‰€æœ‰OEA summaryæ–‡ä»¶"""
        oea_files = {}
        
        cases_dir = self.base_dir / "cases_after_sea"
        if not cases_dir.exists():
            print(f"âŒ æœªæ‰¾åˆ°æ¡ˆä¾‹ç›®å½•: {cases_dir}")
            return oea_files
        
        # éå†GPUç±»å‹ç›®å½•
        for gpu_dir in cases_dir.iterdir():
            if not gpu_dir.is_dir():
                continue
            
            # éå†æ¡ˆä¾‹ç›®å½•
            for case_dir in gpu_dir.iterdir():
                if not case_dir.is_dir():
                    continue
                
                # æŸ¥æ‰¾oea_summary_*.jsonæ–‡ä»¶
                summary_files = list(case_dir.glob("oea_summary_*.json"))
                if summary_files:
                    case_name = case_dir.name
                    oea_files[case_name] = summary_files[0]
        
        print(f"ğŸ“ æ‰¾åˆ° {len(oea_files)} ä¸ªOEA summaryæ–‡ä»¶")
        return oea_files
    
    def load_oea_data(self, oea_file: Path) -> Optional[Dict]:
        """åŠ è½½OEAæ•°æ®"""
        try:
            with open(oea_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            print(f"âŒ åŠ è½½OEAæ•°æ®å¤±è´¥ {oea_file}: {e}")
            return None
    
    def parse_case_name(self, case_name: str) -> Dict[str, Any]:
        """ä»æ¡ˆä¾‹åç§°è§£æä¿¡æ¯
        æ ¼å¼: ModelName_batchX_inputY_outputZ
        ä¾‹å¦‚: Qwen3-32B_batch8_input1024_output10
        """
        parts = case_name.split('_')
        
        info = {
            'model_name': parts[0] if parts else None,
            'batch_size': None,
            'input_size': None,
            'output_size': None
        }
        
        for part in parts:
            if part.startswith('batch'):
                info['batch_size'] = int(part.replace('batch', ''))
            elif part.startswith('input'):
                info['input_size'] = int(part.replace('input', ''))
            elif part.startswith('output'):
                info['output_size'] = int(part.replace('output', ''))
        
        return info
    
    def map_gpu_type_to_spec_key(self, gpu_type: str) -> str:
        """å°†GPUç±»å‹æ˜ å°„åˆ°ç¡¬ä»¶è§„æ ¼é”®"""
        mapping = {
            'H20': 'NVIDIA_H20_SXM5_96GB',
            'H800': 'NVIDIA_H800',
            'A100': 'NVIDIA_A100_SXM4_80GB',
            'A800': 'NVIDIA_A800_SXM4_80GB',
            'L20': 'NVIDIA_L20'
        }
        return mapping.get(gpu_type, gpu_type)
    
    def integrate_all_data(self) -> List[Dict]:
        """æ•´åˆæ‰€æœ‰æ•°æ®"""
        print("ğŸš€ å¼€å§‹SGLangæ¡†æ¶æ•°æ®æ•´åˆ...")
        print("=" * 60)
        
        # 1. åŠ è½½SEA+MEAæ•°æ®
        sea_mea_df = self.load_sea_mea_data()
        if sea_mea_df.empty:
            print("âŒ SEA+MEAæ•°æ®ä¸ºç©ºï¼Œæ— æ³•ç»§ç»­")
            return []
        
        # 2. æŸ¥æ‰¾OEA summaryæ–‡ä»¶
        print("\nğŸ“ æŸ¥æ‰¾OEAæ•°æ®...")
        oea_files = self.find_oea_summary_files()
        
        # 3. æ•´åˆæ•°æ®
        print("\nğŸ”„ æ•´åˆæ•°æ®...")
        integrated_data = []
        
        for idx, row in sea_mea_df.iterrows():
            case_name = row['pod_name']
            print(f"\nå¤„ç†æ¡ˆä¾‹ [{idx+1}/{len(sea_mea_df)}]: {case_name}")
            
            # è§£ææ¡ˆä¾‹åç§°
            case_info = self.parse_case_name(case_name)
            
            # æ„å»ºæ¡ˆä¾‹æ•°æ®
            case_data = {
                'case_name': case_name,
                'sea_mea_data': row.to_dict(),
                'case_info': case_info
            }
            
            # æŸ¥æ‰¾å¯¹åº”çš„OEAæ•°æ®
            if case_name in oea_files:
                oea_file = oea_files[case_name]
                oea_data = self.load_oea_data(oea_file)
                if oea_data:
                    case_data['oea_data'] = oea_data
                    case_data['oea_file'] = str(oea_file)
                    print(f"   âœ… OEAæ•°æ®åŠ è½½æˆåŠŸ")
                else:
                    print(f"   âŒ OEAæ•°æ®åŠ è½½å¤±è´¥")
            else:
                print(f"   âš ï¸  æœªæ‰¾åˆ°OEAæ•°æ®")
            
            integrated_data.append(case_data)
        
        print(f"\nâœ… æ•°æ®æ•´åˆå®Œæˆï¼Œå…±å¤„ç† {len(integrated_data)} ä¸ªæ¡ˆä¾‹")
        return integrated_data
    
    def extract_key_metrics(self, case_data: Dict) -> Dict:
        """æå–å…³é”®æŒ‡æ ‡ï¼Œä¿æŒä¸vLLMæ¡†æ¶ä¸€è‡´çš„åˆ—ç»“æ„"""
        metrics = {}
        
        # SEA+MEAå±‚æ•°æ®
        sea_mea = case_data.get('sea_mea_data', {})
        case_info = case_data.get('case_info', {})
        
        # åŸºæœ¬ä¿¡æ¯ - ç”Ÿæˆcase_idï¼ˆä½¿ç”¨ç´¢å¼•ï¼‰
        metrics['case_id'] = None  # åç»­åœ¨å¯¼å‡ºæ—¶å¡«å……
        metrics['pod_name'] = sea_mea.get('pod_name')
        metrics['model_name'] = sea_mea.get('model_name')
        metrics['gpu_type'] = sea_mea.get('GPU_type')
        metrics['gpu_num'] = 1  # SGLangæ¡ˆä¾‹é»˜è®¤ä¸º1
        
        # åˆ†ç»„ä¿¡æ¯ - SGLangæ¡ˆä¾‹æš‚æ—¶ä¸åˆ†ç»„
        metrics['group_name'] = 'SGLang Framework'
        metrics['group_id'] = 0
        
        # SEAå±‚æŒ‡æ ‡
        metrics['sea_qps'] = sea_mea.get('qps')
        metrics['sea_fpr'] = sea_mea.get('FPR')
        metrics['sea_token_size'] = sea_mea.get('token_size')
        
        # MEAå±‚æŒ‡æ ‡
        metrics['mea_iips'] = sea_mea.get('IIPS')
        metrics['mea_total_iterations'] = sea_mea.get('iteration')
        metrics['mea_avg_iteration_duration_us'] = None  # å¯ä»¥ä»IIPSè®¡ç®—
        if metrics['mea_iips'] and metrics['mea_iips'] > 0:
            metrics['mea_avg_iteration_duration_us'] = 1_000_000 / metrics['mea_iips']
        metrics['mea_std_iteration_duration_us'] = None  # CSVä¸­æ²¡æœ‰æ­¤æ•°æ®
        metrics['mea_mie'] = sea_mea.get('MIE')
        
        # GPUåˆ©ç”¨ç‡
        metrics['gpu_utilization'] = sea_mea.get('GPU_util')
        
        # OEAå±‚æŒ‡æ ‡
        oea_data = case_data.get('oea_data', {})
        if oea_data:
            overall_metrics = oea_data.get('overall_metrics', {})
            bottleneck_ranking = oea_data.get('bottleneck_ranking', [])
            
            # æ•´ä½“æ•ˆç‡æŒ‡æ ‡
            metrics['oea_overall_efficiency'] = overall_metrics.get('overall_efficiency')
            metrics['oea_total_compute_time_us'] = overall_metrics.get('total_kernel_time_us')
            metrics['oea_total_flops'] = overall_metrics.get('total_flops')
            
            # å†…å­˜åˆ©ç”¨ç‡ - ä»hardware_specsè®¡ç®—
            hw_specs = oea_data.get('hardware_specs', {})
            total_memory_access = overall_metrics.get('total_memory_access', 0)
            total_time_s = overall_metrics.get('total_kernel_time_us', 0) / 1_000_000
            peak_bandwidth_gbps = hw_specs.get('pi', 0)  # SGLangä½¿ç”¨piå­—æ®µè¡¨ç¤ºå¸¦å®½(GB/s)
            
            if total_time_s > 0 and peak_bandwidth_gbps > 0:
                actual_bandwidth_gbps = total_memory_access / total_time_s
                metrics['oea_memory_utilization'] = actual_bandwidth_gbps / peak_bandwidth_gbps
            else:
                metrics['oea_memory_utilization'] = None
            
            # æå–å‰5ä¸ªç“¶é¢ˆç®—å­
            for i in range(5):
                prefix = f'oea_bottleneck_{i+1}'
                if i < len(bottleneck_ranking):
                    bottleneck = bottleneck_ranking[i]
                    metrics[f'{prefix}_operator'] = bottleneck.get('operator_type')
                    metrics[f'{prefix}_score'] = bottleneck.get('bottleneck_score')
                    metrics[f'{prefix}_efficiency'] = bottleneck.get('efficiency_degree')
                    metrics[f'{prefix}_time_proportion'] = bottleneck.get('kernel_time_proportion')
                else:
                    # å¡«å……ç©ºå€¼
                    metrics[f'{prefix}_operator'] = None
                    metrics[f'{prefix}_score'] = None
                    metrics[f'{prefix}_efficiency'] = None
                    metrics[f'{prefix}_time_proportion'] = None
        else:
            # OEAæ•°æ®ç¼ºå¤±ï¼Œå¡«å……ç©ºå€¼
            metrics['oea_overall_efficiency'] = None
            metrics['oea_total_compute_time_us'] = None
            metrics['oea_total_flops'] = None
            metrics['oea_memory_utilization'] = None
            
            for i in range(5):
                prefix = f'oea_bottleneck_{i+1}'
                metrics[f'{prefix}_operator'] = None
                metrics[f'{prefix}_score'] = None
                metrics[f'{prefix}_efficiency'] = None
                metrics[f'{prefix}_time_proportion'] = None
        
        # ç¡¬ä»¶è§„æ ¼
        gpu_type = metrics.get('gpu_type', '')
        gpu_spec_key = self.map_gpu_type_to_spec_key(gpu_type)
        if gpu_spec_key in self.hardware_specs:
            hw_spec = self.hardware_specs[gpu_spec_key]
            metrics['hw_mem_bandwidth_gbps'] = hw_spec['mem_bandwidth_gbps']
            metrics['hw_fp16_tflops'] = hw_spec['fp16_tflops']
            metrics['hw_memory_size_gb'] = hw_spec['memory_size_gb']
        else:
            metrics['hw_mem_bandwidth_gbps'] = None
            metrics['hw_fp16_tflops'] = None
            metrics['hw_memory_size_gb'] = None
        
        return metrics
    
    def export_to_csv(self, integrated_data: List[Dict], output_file: str = "sglang_integrated_data.csv"):
        """å¯¼å‡ºä¸ºCSVæ ¼å¼ï¼Œä¿æŒä¸vLLMæ¡†æ¶ä¸€è‡´çš„åˆ—é¡ºåº"""
        print(f"\nğŸ“¤ å¯¼å‡ºæ•°æ®åˆ° {output_file}...")
        
        # æå–å…³é”®æŒ‡æ ‡
        metrics_list = []
        for idx, case_data in enumerate(integrated_data):
            metrics = self.extract_key_metrics(case_data)
            metrics['case_id'] = idx + 1  # å¡«å……case_id
            metrics_list.append(metrics)
        
        # åˆ›å»ºDataFrame
        df = pd.DataFrame(metrics_list)
        
        # ç¡®ä¿åˆ—é¡ºåºä¸vLLMæ¡†æ¶ä¸€è‡´
        column_order = [
            'case_id', 'pod_name', 'model_name', 'gpu_type', 'gpu_num',
            'group_name', 'group_id',
            'sea_qps', 'sea_fpr', 'sea_token_size',
            'mea_iips', 'mea_total_iterations', 'mea_avg_iteration_duration_us',
            'mea_std_iteration_duration_us', 'mea_mie',
            'gpu_utilization',
            'oea_overall_efficiency', 'oea_total_compute_time_us', 'oea_total_flops',
            'oea_memory_utilization',
            'oea_bottleneck_1_operator', 'oea_bottleneck_1_score',
            'oea_bottleneck_1_efficiency', 'oea_bottleneck_1_time_proportion',
            'oea_bottleneck_2_operator', 'oea_bottleneck_2_score',
            'oea_bottleneck_2_efficiency', 'oea_bottleneck_2_time_proportion',
            'oea_bottleneck_3_operator', 'oea_bottleneck_3_score',
            'oea_bottleneck_3_efficiency', 'oea_bottleneck_3_time_proportion',
            'oea_bottleneck_4_operator', 'oea_bottleneck_4_score',
            'oea_bottleneck_4_efficiency', 'oea_bottleneck_4_time_proportion',
            'oea_bottleneck_5_operator', 'oea_bottleneck_5_score',
            'oea_bottleneck_5_efficiency', 'oea_bottleneck_5_time_proportion',
            'hw_mem_bandwidth_gbps', 'hw_fp16_tflops', 'hw_memory_size_gb'
        ]
        
        # é‡æ–°æ’åºåˆ—
        df = df[column_order]
        
        # å¯¼å‡ºCSV
        df.to_csv(output_file, index=False, encoding='utf-8')
        
        print(f"âœ… æ•°æ®å¯¼å‡ºå®Œæˆ: {output_file}")
        print(f"   å…± {len(df)} è¡Œï¼Œ{len(df.columns)} åˆ—")
        
        return df
    
    def export_to_json(self, integrated_data: List[Dict], output_file: str = "sglang_integrated_data.json"):
        """å¯¼å‡ºä¸ºJSONæ ¼å¼"""
        print(f"\nğŸ“¤ å¯¼å‡ºå®Œæ•´æ•°æ®åˆ° {output_file}...")
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(integrated_data, f, indent=2, ensure_ascii=False)
        
        print(f"âœ… å®Œæ•´æ•°æ®å¯¼å‡ºå®Œæˆ: {output_file}")
        
        return integrated_data
    
    def print_summary(self, df: pd.DataFrame):
        """æ‰“å°æ•°æ®æ‘˜è¦"""
        print("\n" + "=" * 60)
        print("ğŸ“ˆ æ•°æ®æ¦‚è§ˆ")
        print("=" * 60)
        print(f"æ€»æ¡ˆä¾‹æ•°: {len(df)}")
        print(f"æ•°æ®åˆ—æ•°: {len(df.columns)}")
        
        # æŒ‰GPUç±»å‹ç»Ÿè®¡
        if 'gpu_type' in df.columns:
            print("\nğŸ“Š GPUç±»å‹åˆ†å¸ƒ:")
            gpu_stats = df['gpu_type'].value_counts()
            for gpu, count in gpu_stats.items():
                print(f"   {gpu}: {count} ä¸ªæ¡ˆä¾‹")
        
        # æŒ‰æ¨¡å‹ç»Ÿè®¡
        if 'model_name' in df.columns:
            print("\nğŸ“Š æ¨¡å‹åˆ†å¸ƒ:")
            model_stats = df['model_name'].value_counts()
            for model, count in model_stats.items():
                print(f"   {model}: {count} ä¸ªæ¡ˆä¾‹")
        
        # å…³é”®æŒ‡æ ‡ç»Ÿè®¡
        key_metrics = {
            'sea_fpr': 'SEA FPR',
            'mea_iips': 'MEA IIPS',
            'mea_mie': 'MEA MIE',
            'oea_overall_efficiency': 'OEAæ•´ä½“æ•ˆç‡',
            'gpu_utilization': 'GPUåˆ©ç”¨ç‡'
        }
        
        print("\nğŸ“Š å…³é”®æŒ‡æ ‡ç»Ÿè®¡:")
        for metric, name in key_metrics.items():
            if metric in df.columns:
                values = df[metric].dropna()
                if len(values) > 0:
                    print(f"   {name}:")
                    print(f"      å‡å€¼={values.mean():.4f}, æ ‡å‡†å·®={values.std():.4f}")
                    print(f"      èŒƒå›´=[{values.min():.4f}, {values.max():.4f}]")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ¯ SGLangæ¡†æ¶ LLM-Prof æ•°æ®æ•´åˆå·¥å…·")
    print("=" * 60)
    
    # åˆ›å»ºæ•°æ®æ•´åˆå™¨
    integrator = SGLangDataIntegrator()
    
    # æ•´åˆæ‰€æœ‰æ•°æ®
    integrated_data = integrator.integrate_all_data()
    
    if not integrated_data:
        print("\nâŒ æ²¡æœ‰æ•°æ®å¯ä»¥å¯¼å‡º")
        return
    
    # å¯¼å‡ºæ•°æ®
    print("\n" + "=" * 60)
    print("ğŸ“Š å¯¼å‡ºæ•°æ®")
    print("=" * 60)
    
    df = integrator.export_to_csv(integrated_data)
    integrator.export_to_json(integrated_data)
    
    # æ˜¾ç¤ºæ•°æ®æ‘˜è¦
    integrator.print_summary(df)
    
    print("\nğŸ‰ æ•°æ®æ•´åˆå®Œæˆï¼")
    print("=" * 60)

if __name__ == "__main__":
    main()