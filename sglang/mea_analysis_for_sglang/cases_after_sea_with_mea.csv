pod_name,model_name,batch_size,token_size,GPU_type,iteration,GPU_util,qps,seq_len,FPR,IIPS,MIE
Qwen3-30B-A3B_batch1_input2048_output10,Qwen3-30B-A3B,1,2048,A100,10,86.1,1,2048,268.632,33.975812,7.906566
Qwen3-14B_batch4_input2048_output10,Qwen3-14B,4,8192,H800,10,93.64,4,2048,231.5249,18.833618,49.172686
Qwen2.5-3B_batch1_input1024_output10,Qwen2.5-3B,1,1024,A100,10,56.55,1,1024,176.436,49.584591,3.558283
Qwen2.5-3B_batch1_input1024_output10,Qwen2.5-3B,1,1024,A800,10,56.55,1,1024,176.436,49.584591,3.558283
Qwen3-14B_batch1_input1024_output10,Qwen3-14B,1,1024,H20,10,93.71,1,1024,138.6908,28.918649,4.795895
Llama-3.1-8B_batch1_input1024_output10,Llama-3.1-8B,1,1024,H20,10,92.97,1,1024,137.5956,48.915593,2.812919
Qwen2.5-14B_batch1_input1024_output10,Qwen2.5-14B,1,1024,H20,10,91.9,1,1024,136.012,27.506971,4.944638
Qwen3-8B_batch1_input1024_output10,Qwen3-8B,1,1024,H20,10,91.19,1,1024,134.9612,46.471033,2.904201
Qwen2.5-7B_batch1_input1024_output10,Qwen2.5-7B,1,1024,H20,10,91.08,1,1024,134.7984,53.222708,2.532723
Llama-3.2-3B_batch1_input1024_output10,Llama-3.2-3B,1,1024,H20,10,84.78,1,1024,125.4744,86.548753,1.449754
Qwen3-30B-A3B_batch1_input2048_output10,Qwen3-30B-A3B,1,2048,H20,10,83.46,1,2048,123.52079999999998,32.896449,3.754837
Qwen3-4B_batch1_input1024_output10,Qwen3-4B,1,1024,H20,10,82.12,1,1024,121.5376,66.29306,1.833338
Qwen3-32B_batch8_input1024_output10,Qwen3-32B,8,8192,H800,10,97.18,8,1024,120.138775,8.817449,109.000939
