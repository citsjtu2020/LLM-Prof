#!/usr/bin/env python3
"""
MEA (Model Efficiency Analyzer) for SGLang Framework
åŸºäº LLM-Prof è®ºæ–‡å®ç°çš„ç®€åŒ–ç‰ˆ MEA åˆ†æå™¨ï¼Œä¸“é—¨ç”¨äº SGLang æ¡†æ¶
æ”¹è¿›ç‰ˆæœ¬ï¼šè‡ªåŠ¨æ ¹æ® GPU_type å’Œ pod_name å®šä½ trace æ–‡ä»¶
"""

import pandas as pd
import json
import gzip
import os
import sys
import logging
import numpy as np
from typing import Dict, Any, Optional, List, Tuple
import argparse
from pathlib import Path
import re
import glob

# Configure logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class SGLangMEAAnalyzer:
    """SGLang æ¡†æ¶çš„ç®€åŒ– MEA åˆ†æå™¨ - æ”¹è¿›ç‰ˆ"""
    
    def __init__(self):
        # GPU å³°å€¼ç®—åŠ›é…ç½® (TFLOPs, FP16)
        self.gpu_peak_flops = {
            'A100': 312.0,
            'A800': 312.0, 
            'H800': 989.0,
            'H20': 148.0,
            'L20': 59.7,
            'H100': 989.0,
            'V100': 125.0,
        }
        
        # å›ºå®šè¿­ä»£æ•° (SGLang: 1 prefill + 9 decode)
        self.fixed_iterations = 10
        
        # ç¼“å­˜å·²æ‰«æçš„ç›®å½•ç»“æ„
        self.trace_file_cache = {}
        
    def get_gpu_peak_flops(self, gpu_type: str) -> float:
        """è·å– GPU å³°å€¼ç®—åŠ›"""
        gpu_clean = gpu_type.strip().upper()
        
        # å°è¯•ç²¾ç¡®åŒ¹é…
        for key, value in self.gpu_peak_flops.items():
            if key.upper() == gpu_clean:
                return value
        
        # å°è¯•éƒ¨åˆ†åŒ¹é…
        for key, value in self.gpu_peak_flops.items():
            if key.upper() in gpu_clean or gpu_clean in key.upper():
                return value
        
        # é»˜è®¤å€¼
        logger.warning(f"Unknown GPU type: {gpu_type}, using default H20 peak flops")
        return 148.0
    
    def scan_trace_files(self, base_dir: str = ".") -> Dict[str, List[str]]:
        """
        æ‰«æå¹¶ç¼“å­˜æ‰€æœ‰ trace æ–‡ä»¶çš„ä½ç½®
        
        Args:
            base_dir: åŸºç¡€ç›®å½•
            
        Returns:
            æŒ‰ GPU ç±»å‹åˆ†ç»„çš„ trace æ–‡ä»¶å­—å…¸
        """
        if self.trace_file_cache:
            return self.trace_file_cache
        
        logger.info(f"Scanning trace files in {base_dir}...")
        
        # ä½¿ç”¨ glob æ¨¡å¼åŒ¹é…æ‰€æœ‰ .trace.json.gz æ–‡ä»¶
        pattern = os.path.join(base_dir, "**", "*.trace.json.gz")
        trace_files = glob.glob(pattern, recursive=True)
        
        logger.info(f"Found {len(trace_files)} trace files")
        
        # æŒ‰ GPU ç±»å‹åˆ†ç»„
        gpu_trace_map = {}
        
        for trace_file in trace_files:
            # ä»è·¯å¾„ä¸­æå– GPU ç±»å‹
            path_parts = Path(trace_file).parts
            
            # æŸ¥æ‰¾å¯èƒ½çš„ GPU ç±»å‹ç›®å½•
            gpu_type = None
            for part in path_parts:
                if part.upper() in ['A100', 'A800', 'H800', 'H20', 'L20', 'H100', 'V100']:
                    gpu_type = part.upper()
                    break
            
            if gpu_type:
                if gpu_type not in gpu_trace_map:
                    gpu_trace_map[gpu_type] = []
                gpu_trace_map[gpu_type].append(trace_file)
            else:
                # å¦‚æœæ— æ³•ä»è·¯å¾„ç¡®å®š GPU ç±»å‹ï¼Œæ”¾å…¥é€šç”¨åˆ—è¡¨
                if 'UNKNOWN' not in gpu_trace_map:
                    gpu_trace_map['UNKNOWN'] = []
                gpu_trace_map['UNKNOWN'].append(trace_file)
        
        self.trace_file_cache = gpu_trace_map
        
        # æ‰“å°æ‰«æç»“æœ
        for gpu_type, files in gpu_trace_map.items():
            logger.info(f"  {gpu_type}: {len(files)} files")
        
        return gpu_trace_map
    
    def find_trace_file_optimized(self, pod_name: str, gpu_type: str, base_dir: str = ".") -> Optional[str]:
        """
        ä¼˜åŒ–çš„ trace æ–‡ä»¶æŸ¥æ‰¾æ–¹æ³•
        
        Args:
            pod_name: pod åç§°
            gpu_type: GPU ç±»å‹
            base_dir: åŸºç¡€ç›®å½•
            
        Returns:
            trace æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæœªæ‰¾åˆ°è¿”å› None
        """
        # ç¡®ä¿å·²æ‰«ææ–‡ä»¶
        gpu_trace_map = self.scan_trace_files(base_dir)
        
        # æ ‡å‡†åŒ– GPU ç±»å‹
        gpu_type_normalized = gpu_type.upper()
        
        # æ„å»ºå€™é€‰æ–‡ä»¶åæ¨¡å¼
        expected_filename = f"{pod_name}.trace.json.gz"
        
        # ä¼˜å…ˆåœ¨å¯¹åº” GPU ç±»å‹ç›®å½•ä¸­æŸ¥æ‰¾
        search_lists = []
        if gpu_type_normalized in gpu_trace_map:
            search_lists.append((gpu_type_normalized, gpu_trace_map[gpu_type_normalized]))
        
        # å¦‚æœåœ¨å¯¹åº” GPU ç±»å‹ä¸­æ‰¾ä¸åˆ°ï¼Œæœç´¢æ‰€æœ‰æ–‡ä»¶
        for gt, files in gpu_trace_map.items():
            if gt != gpu_type_normalized:
                search_lists.append((gt, files))
        
        # åœ¨æ¯ä¸ªæœç´¢åˆ—è¡¨ä¸­æŸ¥æ‰¾
        for search_gpu_type, file_list in search_lists:
            # ç²¾ç¡®åŒ¹é…
            for trace_file in file_list:
                if os.path.basename(trace_file) == expected_filename:
                    logger.info(f"Found exact match: {trace_file} (expected GPU: {gpu_type}, found in: {search_gpu_type})")
                    return trace_file
            
            # éƒ¨åˆ†åŒ¹é…ï¼ˆåŒ…å« pod_nameï¼‰
            for trace_file in file_list:
                if pod_name in os.path.basename(trace_file):
                    logger.info(f"Found partial match: {trace_file} (expected GPU: {gpu_type}, found in: {search_gpu_type})")
                    return trace_file
        
        logger.warning(f"Trace file not found for pod: {pod_name}, GPU: {gpu_type}")
        return None
    
    def extract_trace_duration(self, trace_file: str) -> Optional[float]:
        """
        ä» trace.json.gz æ–‡ä»¶ä¸­æå–æ€»æ‰§è¡Œæ—¶é—´
        
        Args:
            trace_file: trace æ–‡ä»¶è·¯å¾„
            
        Returns:
            æ€»æ‰§è¡Œæ—¶é—´ (ç§’)ï¼Œå¦‚æœå¤±è´¥è¿”å› None
        """
        try:
            logger.debug(f"Processing trace file: {trace_file}")
            
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨
            if not os.path.exists(trace_file):
                logger.warning(f"Trace file not found: {trace_file}")
                return None
            
            # è¯»å–å‹ç¼©çš„ JSON æ–‡ä»¶
            with gzip.open(trace_file, 'rt', encoding='utf-8') as f:
                trace_data = json.load(f)
            
            # æå– traceEvents
            trace_events = trace_data.get('traceEvents', [])
            if not trace_events:
                logger.warning(f"No trace events found in {trace_file}")
                return None
            
            # æ‰¾åˆ°ç¬¬ä¸€ä¸ªå’Œæœ€åä¸€ä¸ªäº‹ä»¶çš„æ—¶é—´æˆ³
            timestamps = []
            for event in trace_events:
                ts = event.get('ts')
                dur = event.get('dur', 0)
                if ts is not None:
                    timestamps.append(ts)
                    if dur > 0:
                        timestamps.append(ts + dur)
            
            if len(timestamps) < 2:
                logger.warning(f"Insufficient timestamps in {trace_file}")
                return None
            
            # è®¡ç®—æ€»æ—¶é—´è·¨åº¦ (å¾®ç§’è½¬ç§’)
            min_ts = min(timestamps)
            max_ts = max(timestamps)
            duration_us = max_ts - min_ts
            duration_s = duration_us / 1_000_000.0
            
            logger.debug(f"Extracted duration: {duration_s:.6f} seconds ({duration_us:.1f} Î¼s)")
            return duration_s
            
        except Exception as e:
            logger.error(f"Error processing trace file {trace_file}: {e}")
            return None
    
    def calculate_iips(self, duration_s: float) -> float:
        """
        è®¡ç®— IIPS (Inference Iterations Per Second)
        
        Args:
            duration_s: æ€»æ‰§è¡Œæ—¶é—´ (ç§’)
            
        Returns:
            IIPS å€¼
        """
        if duration_s <= 0:
            return 0.0
        
        iips = self.fixed_iterations / duration_s
        return iips
    
    def calculate_mie(self, iips: float, gpu_type: str, gpu_util: float) -> float:
        """
        è®¡ç®— MIE (Model Inference Efficiency)
        
        æ ¹æ®è®ºæ–‡å…¬å¼ï¼šMIE = (F_peak Ã— u_GPU Ã— N_GPU) / IIPS
        
        Args:
            iips: æ¯ç§’æ¨ç†è¿­ä»£æ•°
            gpu_type: GPU å‹å·
            gpu_util: GPU åˆ©ç”¨ç‡ (ç™¾åˆ†æ¯”)
            
        Returns:
            MIE å€¼ (TFLOPs per iteration)
        """
        if iips <= 0:
            return float('inf')
        
        f_peak = self.get_gpu_peak_flops(gpu_type)  # TFLOPs
        u_gpu = gpu_util / 100.0  # è½¬æ¢ä¸º [0,1]
        n_gpu = 1  # SGLang å•å¡æ¨ç†
        
        mie = (f_peak * u_gpu * n_gpu) / iips
        return mie
    
    def analyze_case(self, row: pd.Series, base_dir: str = ".") -> Dict[str, Any]:
        """
        åˆ†æå•ä¸ªæ¡ˆä¾‹
        
        Args:
            row: CSV è¡Œæ•°æ®
            base_dir: åŸºç¡€ç›®å½•
            
        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        pod_name = row['pod_name']
        gpu_type = row['GPU_type']
        gpu_util = row['GPU_util']
        
        logger.info(f"Analyzing case: {pod_name} on {gpu_type}")
        
        # ä½¿ç”¨ä¼˜åŒ–çš„æ–‡ä»¶æŸ¥æ‰¾æ–¹æ³•
        trace_file = self.find_trace_file_optimized(pod_name, gpu_type, base_dir)
        if trace_file is None:
            return {
                'iips': 0.0,
                'mie': float('inf'),
                'duration_s': 0.0,
                'error': 'Trace file not found'
            }
        
        # æå–æ‰§è¡Œæ—¶é—´
        duration_s = self.extract_trace_duration(trace_file)
        if duration_s is None:
            return {
                'iips': 0.0,
                'mie': float('inf'),
                'duration_s': 0.0,
                'error': 'Failed to extract duration'
            }
        
        # è®¡ç®— IIPS
        iips = self.calculate_iips(duration_s)
        
        # è®¡ç®— MIE
        mie = self.calculate_mie(iips, gpu_type, gpu_util)
        
        result = {
            'iips': round(iips, 6),
            'mie': round(mie, 6) if mie != float('inf') else float('inf'),
            'duration_s': round(duration_s, 6),
            'trace_file': trace_file,
            'f_peak': self.get_gpu_peak_flops(gpu_type),
            'u_gpu': gpu_util / 100.0,
            'n_gpu': 1,
            'iterations': self.fixed_iterations
        }
        
        logger.info(f"Results for {pod_name}: IIPS={iips:.6f}, MIE={mie:.6f}")
        return result
    
    def analyze_all_cases(self, input_csv: str, output_csv: str, base_dir: str = ".") -> None:
        """
        åˆ†ææ‰€æœ‰ç­›é€‰åçš„æ¡ˆä¾‹
        
        Args:
            input_csv: è¾“å…¥ CSV æ–‡ä»¶ (cases_after_sea.csv)
            output_csv: è¾“å‡º CSV æ–‡ä»¶
            base_dir: åŸºç¡€ç›®å½•
        """
        logger.info(f"Starting MEA analysis for all cases")
        logger.info(f"Input: {input_csv}")
        logger.info(f"Output: {output_csv}")
        logger.info(f"Base directory: {base_dir}")
        
        # é¢„å…ˆæ‰«ææ‰€æœ‰ trace æ–‡ä»¶
        self.scan_trace_files(base_dir)
        
        # è¯»å–è¾“å…¥ CSV
        df = pd.read_csv(input_csv)
        logger.info(f"Loaded {len(df)} cases from {input_csv}")
        
        # æ˜¾ç¤ºæ¡ˆä¾‹æ¦‚è§ˆ
        logger.info("Cases overview:")
        gpu_counts = df['GPU_type'].value_counts()
        for gpu_type, count in gpu_counts.items():
            logger.info(f"  {gpu_type}: {count} cases")
        
        # åªæ·»åŠ å¿…è¦çš„ä¸¤åˆ—ï¼šIIPS å’Œ MIE
        df['IIPS'] = 0.0
        df['MIE'] = float('inf')
        
        # åˆ†ææ¯ä¸ªæ¡ˆä¾‹
        successful_cases = 0
        failed_cases = 0
        
        for idx, row in df.iterrows():
            try:
                result = self.analyze_case(row, base_dir)
                
                # æ›´æ–°ç»“æœ - åªæ›´æ–° IIPS å’Œ MIE
                df.at[idx, 'IIPS'] = result['iips']
                df.at[idx, 'MIE'] = result['mie']
                
                if result.get('error'):
                    failed_cases += 1
                    logger.warning(f"Failed to analyze {row['pod_name']}: {result['error']}")
                else:
                    successful_cases += 1
                    
            except Exception as e:
                logger.error(f"Error analyzing case {row['pod_name']}: {e}")
                df.at[idx, 'IIPS'] = 0.0
                df.at[idx, 'MIE'] = float('inf')
                failed_cases += 1
        
        # ä¿å­˜ç»“æœ
        df.to_csv(output_csv, index=False)
        logger.info(f"Results saved to {output_csv}")
        
        # ç”Ÿæˆç»Ÿè®¡æŠ¥å‘Š
        self._generate_analysis_report(df, successful_cases, failed_cases)
    
    def _generate_analysis_report(self, df: pd.DataFrame, successful_cases: int, failed_cases: int) -> None:
        """ç”Ÿæˆåˆ†ææŠ¥å‘Š"""
        logger.info("\n" + "="*60)
        logger.info("MEA Analysis Report")
        logger.info("="*60)
        
        logger.info(f"Total cases: {len(df)}")
        logger.info(f"Successful analyses: {successful_cases}")
        logger.info(f"Failed analyses: {failed_cases}")
        logger.info(f"Success rate: {successful_cases/len(df)*100:.1f}%")
        
        # ç»Ÿè®¡æœ‰æ•ˆç»“æœ
        valid_results = df[df['IIPS'] > 0]
        if len(valid_results) > 0:
            logger.info(f"\nIIPS Statistics:")
            logger.info(f"  Mean: {valid_results['IIPS'].mean():.6f}")
            logger.info(f"  Std:  {valid_results['IIPS'].std():.6f}")
            logger.info(f"  Min:  {valid_results['IIPS'].min():.6f}")
            logger.info(f"  Max:  {valid_results['IIPS'].max():.6f}")
            
            finite_mie = valid_results[valid_results['MIE'] != float('inf')]
            if len(finite_mie) > 0:
                logger.info(f"\nMIE Statistics:")
                logger.info(f"  Mean: {finite_mie['MIE'].mean():.6f}")
                logger.info(f"  Std:  {finite_mie['MIE'].std():.6f}")
                logger.info(f"  Min:  {finite_mie['MIE'].min():.6f}")
                logger.info(f"  Max:  {finite_mie['MIE'].max():.6f}")
        
        # æŒ‰ GPU ç±»å‹ç»Ÿè®¡
        logger.info(f"\nResults by GPU Type:")
        for gpu_type in df['GPU_type'].unique():
            gpu_data = valid_results[valid_results['GPU_type'] == gpu_type]
            if len(gpu_data) > 0:
                avg_iips = gpu_data['IIPS'].mean()
                avg_mie = gpu_data[gpu_data['MIE'] != float('inf')]['MIE'].mean()
                logger.info(f"  {gpu_type}: {len(gpu_data)}/{len(df[df['GPU_type'] == gpu_type])} successful, "
                           f"avg IIPS={avg_iips:.6f}, avg MIE={avg_mie:.6f}")
            else:
                total_gpu_cases = len(df[df['GPU_type'] == gpu_type])
                logger.info(f"  {gpu_type}: 0/{total_gpu_cases} successful")
        
        # å¤±è´¥æ¡ˆä¾‹åˆ†æ
        if failed_cases > 0:
            logger.info(f"\nFailed Cases:")
            failed_results = df[(df['IIPS'] == 0) | (df['MIE'] == float('inf'))]
            logger.info(f"  Total failed cases: {len(failed_results)}")
            for idx, row in failed_results.iterrows():
                logger.info(f"    {row['pod_name']} ({row['GPU_type']})")
        
        logger.info("="*60)

def main():
    parser = argparse.ArgumentParser(description='MEA Analysis for SGLang Framework - Improved Version')
    parser.add_argument('--input', '-i', default='cases_after_sea.csv',
                        help='Input CSV file (default: cases_after_sea.csv)')
    parser.add_argument('--output', '-o', default='cases_after_sea_with_mea.csv',
                        help='Output CSV file (default: cases_after_sea_with_mea.csv)')
    parser.add_argument('--base-dir', '-d', default='.',
                        help='Base directory containing GPU folders (default: current directory)')
    parser.add_argument('--verbose', '-v', action='store_true',
                        help='Enable verbose logging')
    
    args = parser.parse_args()
    
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    # æ£€æŸ¥è¾“å…¥æ–‡ä»¶
    if not os.path.exists(args.input):
        logger.error(f"Input file not found: {args.input}")
        sys.exit(1)
    
    # æ£€æŸ¥åŸºç¡€ç›®å½•
    if not os.path.exists(args.base_dir):
        logger.error(f"Base directory not found: {args.base_dir}")
        sys.exit(1)
    
    # åˆ›å»ºåˆ†æå™¨
    analyzer = SGLangMEAAnalyzer()
    
    try:
        # æ‰§è¡Œåˆ†æ
        analyzer.analyze_all_cases(args.input, args.output, args.base_dir)
        logger.info(f"âœ… MEA analysis completed successfully!")
        logger.info(f"ğŸ“ Results saved to: {args.output}")
        
    except Exception as e:
        logger.error(f"âŒ MEA analysis failed: {e}")
        import traceback
        logger.error(traceback.format_exc())
        sys.exit(1)

if __name__ == "__main__":
    main()