pod_name,model_name,batch_size,token_size,GPU_type,iteration,GPU_util,qps,seq_len,FPR
Qwen2.5-14B_batch1_input2048_output10,Qwen2.5-14B,1,2048,L20,10,96.78,1,2048,115.6521
Qwen2.5-3B_batch1_input2048_output10,Qwen2.5-3B,1,2048,L20,10,89.74,1,2048,107.2393
Qwen3-14B_batch8_input128_output10,Qwen3-14B,8,1024,H800,10,69.95,8,128,86.4756875
Qwen2.5-14B_batch8_input128_output10,Qwen2.5-14B,8,1024,H800,10,66.27,8,128,81.9262875
Llama-3.1-8B_batch8_input128_output10,Llama-3.1-8B,8,1024,H800,10,64.0,8,128,79.12
Qwen2.5-7B_batch8_input128_output10,Qwen2.5-7B,8,1024,H800,10,57.0,8,128,70.46624999999999
Llama-3.2-3B_batch8_input128_output10,Llama-3.2-3B,8,1024,H800,10,39.55,8,128,48.8936875
Qwen3-30B-A3B_batch1_input128_output10,Qwen3-30B-A3B,1,128,H20,10,31.12,1,128,46.05760000000001
Qwen2.5-3B_batch8_input128_output10,Qwen2.5-3B,8,1024,H800,10,36.26,8,128,44.826425
Qwen2.5-32B_batch8_input128_output10,Qwen2.5-32B,8,1024,A100,10,92.23,8,128,35.9697
Qwen3-14B_batch8_input128_output10,Qwen3-14B,8,1024,A800,10,90.43,8,128,35.267700000000005
Qwen3-14B_batch8_input128_output10,Qwen3-14B,8,1024,A100,10,89.97,8,128,35.0883
Qwen3-4B_batch8_input128_output10,Qwen3-4B,8,1024,H800,10,28.22,8,128,34.886975
Qwen2.5-14B_batch8_input128_output10,Qwen2.5-14B,8,1024,A800,10,88.23,8,128,34.4097
