#!/usr/bin/env python3
"""
OEAç»“æœæ•°æ®æå–å™¨ - vLLMç‰ˆæœ¬
ä»å®Œæ•´çš„OEA Stage 4ç»“æœä¸­æå–æ±‡æ€»ä¿¡æ¯ï¼Œå»é™¤è¯¦ç»†çš„kernelçº§åˆ«æ•°æ®

ä¸»è¦åŠŸèƒ½:
1. ä¿ç•™hardware_specsã€bottleneck_rankingã€overall_metricsç­‰æ ¸å¿ƒå­—æ®µ
2. æ·»åŠ end_to_end_infoã€time_breakdownã€linear_analysisã€coverage_analysisã€category_results
3. ç®€åŒ–operator_resultsï¼Œå»é™¤è¯¦ç»†çš„kernelä¿¡æ¯
4. ç”Ÿæˆé€‚åˆæ¨ªå‘å¯¹æ¯”çš„ç²¾ç®€æ•°æ®ç»“æ„ï¼Œä¸åŸOEAç‰ˆæœ¬ä¿æŒä¸€è‡´

ä½¿ç”¨æ–¹æ³•:
python extract_oea_summary_vllm.py \
    --input oea_stage4_Qwen3-14B_batch4_input2048_output10_processed.json \
    --output oea_stage4_Qwen3-14B_batch4_input2048_output10_summary.json
"""

import json
import argparse
import os
from typing import Dict, Any
from datetime import datetime

class OEASummaryExtractorVLLM:
    def __init__(self):
        """åˆå§‹åŒ–vLLM OEAç»“æœæå–å™¨"""
        print("=== vLLM OEAç»“æœæ•°æ®æå–å™¨ ===")
        
        # vLLMçš„Linearç®—å­åˆ—è¡¨
        self.linear_projections = ['qkv_proj', 'o_proj', 'gate_up_proj', 'down_proj', 'lm_head']
        
    def extract_summary_data(self, full_results: Dict[str, Any]) -> Dict[str, Any]:
        """ä»å®Œæ•´çš„OEAç»“æœä¸­æå–æ±‡æ€»æ•°æ®"""
        
        summary_data = {}
        
        # 1. ç›´æ¥ä¿ç•™çš„å­—æ®µ
        preserve_fields = [
            'hardware_specs',
            'bottleneck_ranking',
            'overall_metrics',
            'analysis_version'
        ]
        
        for field in preserve_fields:
            if field in full_results:
                summary_data[field] = full_results[field]
                print(f"âœ“ ä¿ç•™å­—æ®µ: {field}")
        
        # 2. æ„å»ºend_to_end_info
        summary_data['end_to_end_info'] = self._build_end_to_end_info(full_results)
        print(f"âœ“ æ„å»ºå­—æ®µ: end_to_end_info")
        
        # 3. æ„å»ºtime_breakdown
        summary_data['time_breakdown'] = self._build_time_breakdown(full_results)
        print(f"âœ“ æ„å»ºå­—æ®µ: time_breakdown")
        
        # 4. æ„å»ºlinear_analysis
        summary_data['linear_analysis'] = self._build_linear_analysis(full_results)
        print(f"âœ“ æ„å»ºå­—æ®µ: linear_analysis")
        
        # 5. æ„å»ºcoverage_analysis
        summary_data['coverage_analysis'] = self._build_coverage_analysis(full_results)
        print(f"âœ“ æ„å»ºå­—æ®µ: coverage_analysis")
        
        # 6. æ„å»ºcategory_results (æ›¿æ¢category_times)
        summary_data['category_results'] = self._build_category_results(full_results)
        print(f"âœ“ æ„å»ºå­—æ®µ: category_results")
        
        # 7. ç®€åŒ–operator_results
        if 'operator_results' in full_results:
            summary_data['operator_results'] = {}
            
            for operator_type, operator_data in full_results['operator_results'].items():
                simplified_operator = {}
                
                if 'operator_data' in operator_data:
                    op_data = operator_data['operator_data']
                    simplified_op_data = {
                        'total_flops': op_data.get('total_flops', 0),
                        'total_memory_access': op_data.get('total_memory_access', 0),
                        'total_duration_us': op_data.get('total_duration_us', 0),
                        'kernel_count': op_data.get('kernel_count', 0),
                        'data_source': op_data.get('data_source', 'unknown')
                    }
                    
                    if 'prefill_flops' in op_data:
                        simplified_op_data['prefill_flops'] = op_data['prefill_flops']
                    if 'decode_flops' in op_data:
                        simplified_op_data['decode_flops'] = op_data['decode_flops']
                    
                    simplified_operator['operator_data'] = simplified_op_data
                
                for key in ['roofline_params', 'efficiency_metrics', 'time_proportions', 'bottleneck_score']:
                    if key in operator_data:
                        simplified_operator[key] = operator_data[key]
                
                summary_data['operator_results'][operator_type] = simplified_operator
            
            print(f"âœ“ ç®€åŒ–operator_results: {len(summary_data['operator_results'])} ä¸ªç®—å­")
        
        return summary_data
    
    def _build_end_to_end_info(self, full_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºend_to_end_infoå­—æ®µ"""
        overall = full_results.get('overall_metrics', {})
        
        return {
            'total_end_to_end_us': overall.get('total_kernel_time_us', 0),
            'inference_start_time': 0,  # vLLM Stage4æ²¡æœ‰è¿™ä¸ªä¿¡æ¯
            'inference_end_time': overall.get('total_kernel_time_us', 0),
            'data_source': 'stage4_vllm'
        }
    
    def _build_time_breakdown(self, full_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºtime_breakdownå­—æ®µ"""
        overall = full_results.get('overall_metrics', {})
        category_times = full_results.get('category_times', {})
        
        total_kernel_time = overall.get('total_kernel_time_us', 0)
        total_end_to_end = total_kernel_time  # vLLMæ²¡æœ‰idle timeä¿¡æ¯
        
        idle_time = 0
        kernel_utilization = 1.0 if total_end_to_end > 0 else 0
        idle_proportion = 0.0
        
        return {
            'total_end_to_end_us': total_end_to_end,
            'total_kernel_time_us': total_kernel_time,
            'idle_time_us': idle_time,
            'kernel_utilization': kernel_utilization,
            'idle_proportion': idle_proportion,
            'category_times': category_times
        }
    
    def _build_linear_analysis(self, full_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºlinear_analysiså­—æ®µ"""
        operator_results = full_results.get('operator_results', {})
        
        # æå–Linearç®—å­ç»Ÿè®¡
        linear_stats = {}
        linear_total_time = 0
        
        for proj_name in self.linear_projections:
            if proj_name in operator_results:
                op_data = operator_results[proj_name].get('operator_data', {})
                duration_us = op_data.get('total_duration_us', 0)
                linear_total_time += duration_us
                
                linear_stats[proj_name] = {
                    'total_duration_us': duration_us,
                    'total_flops': op_data.get('total_flops', 0),
                    'total_memory_access': op_data.get('total_memory_access', 0),
                    'kernel_count': op_data.get('kernel_count', 0),
                    'data_source': op_data.get('data_source', 'unknown')
                }
        
        # è®¡ç®—è¦†ç›–ç‡
        total_time = full_results.get('overall_metrics', {}).get('total_kernel_time_us', 0)
        linear_coverage = (linear_total_time / total_time) if total_time > 0 else 0
        
        return {
            'analysis_mode': 'vllm_stage4',
            'linear_projections': self.linear_projections,
            'linear_projection_stats': linear_stats,
            'linear_coverage': linear_coverage,
            'linear_total_time_ms': linear_total_time / 1000
        }
    
    def _build_coverage_analysis(self, full_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºcoverage_analysiså­—æ®µ"""
        operator_results = full_results.get('operator_results', {})
        
        # ç»Ÿè®¡æ•°æ®æº
        data_source_stats = {}
        for op_type, op_data in operator_results.items():
            source = op_data.get('operator_data', {}).get('data_source', 'unknown')
            data_source_stats[source] = data_source_stats.get(source, 0) + 1
        
        return {
            'data_source_stats': data_source_stats,
            'total_operators_analyzed': len(operator_results),
            'total_operators_expected': len(self.linear_projections) + 8  # 6ä¸ªlinear + 8ä¸ªélinear
        }
    
    def _build_category_results(self, full_results: Dict[str, Any]) -> Dict[str, Any]:
        """æ„å»ºcategory_resultså­—æ®µï¼ˆæ›¿æ¢category_timesï¼‰"""
        category_times = full_results.get('category_times', {})
        operator_results = full_results.get('operator_results', {})
        
        # ç®—å­åˆ†ç±»
        operator_categories = {
            'compute_intensive': set(self.linear_projections + ['attention', 'moe']),
            'memory_intensive': {'rope', 'layernorm', 'activation', 'reduction'},
            'overhead': {'memory', 'communication'}
        }
        
        category_results = {}
        
        for category, operators in operator_categories.items():
            total_time = category_times.get(category, 0)
            total_flops = 0
            total_memory = 0
            operator_count = 0
            operators_in_category = []
            
            for op_type, op_data in operator_results.items():
                if op_type in operators:
                    op_info = op_data.get('operator_data', {})
                    total_flops += op_info.get('total_flops', 0)
                    total_memory += op_info.get('total_memory_access', 0)
                    operator_count += 1
                    operators_in_category.append(op_type)
            
            category_results[category] = {
                'total_time_us': total_time,
                'total_flops': total_flops,
                'total_memory_access': total_memory,
                'operator_count': operator_count,
                'operators_count': len(operators_in_category)
            }
        
        return category_results
    
    def _estimate_data_size(self, data: Dict[str, Any]) -> int:
        """ä¼°ç®—æ•°æ®å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰"""
        try:
            return len(json.dumps(data, ensure_ascii=False))
        except:
            return 0
    
    def extract_from_file(self, input_file: str, output_file: str) -> bool:
        """ä»æ–‡ä»¶æå–OEAæ±‡æ€»æ•°æ®"""
        
        print(f"\n=== å¼€å§‹æå–OEAæ±‡æ€»æ•°æ® ===")
        print(f"è¾“å…¥æ–‡ä»¶: {input_file}")
        print(f"è¾“å‡ºæ–‡ä»¶: {output_file}")
        
        if not os.path.exists(input_file):
            print(f"âŒ è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
            return False
        
        try:
            print(f"\nğŸ“– è¯»å–å®Œæ•´OEAç»“æœ...")
            with open(input_file, 'r', encoding='utf-8') as f:
                full_results = json.load(f)
            
            print(f"âœ“ æˆåŠŸè¯»å–OEAç»“æœæ–‡ä»¶")
            print(f"  åŸå§‹æ•°æ®åŒ…å«å­—æ®µ: {list(full_results.keys())}")
            
            print(f"\nğŸ”„ æå–æ±‡æ€»æ•°æ®...")
            summary_data = self.extract_summary_data(full_results)
            
            print(f"\nğŸ’¾ ä¿å­˜æ±‡æ€»æ•°æ®...")
            output_dir = os.path.dirname(output_file)
            if output_dir:
                os.makedirs(output_dir, exist_ok=True)
            
            with open(output_file, 'w', encoding='utf-8') as f:
                json.dump(summary_data, f, indent=2, ensure_ascii=False)
            
            print(f"âœ… æˆåŠŸä¿å­˜OEAæ±‡æ€»æ•°æ®åˆ°: {output_file}")
            
            self._print_extraction_summary(summary_data, full_results)
            
            return True
            
        except Exception as e:
            print(f"âŒ æå–è¿‡ç¨‹å‡ºé”™: {str(e)}")
            import traceback
            traceback.print_exc()
            return False
    
    def _print_extraction_summary(self, summary_data: Dict[str, Any], full_results: Dict[str, Any]):
        """æ‰“å°æå–ç»“æœç»Ÿè®¡"""
        
        print(f"\n=== æå–ç»“æœç»Ÿè®¡ ===")
        
        # æ•°æ®å‹ç¼©æ•ˆæœ
        original_size = self._estimate_data_size(full_results)
        summary_size = self._estimate_data_size(summary_data)
        if original_size > 0:
            compression_ratio = summary_size / original_size
            print(f"æ•°æ®å‹ç¼©æ¯”: {compression_ratio:.1%}")
            print(f"åŸå§‹å¤§å°: ~{original_size:,} å­—ç¬¦")
            print(f"ç®€åŒ–å¤§å°: ~{summary_size:,} å­—ç¬¦")
            print(f"å‡å°‘æ•°æ®: {(1-compression_ratio)*100:.1f}%")
        
        # å„éƒ¨åˆ†æ•°æ®ç»Ÿè®¡
        if 'operator_results' in summary_data:
            print(f"\nç®—å­åˆ†æç»“æœ: {len(summary_data['operator_results'])} ä¸ªç®—å­")
        
        if 'bottleneck_ranking' in summary_data:
            print(f"ç“¶é¢ˆæ’å: {len(summary_data['bottleneck_ranking'])} ä¸ªç®—å­")
        
        if 'category_results' in summary_data:
            print(f"ç±»åˆ«åˆ†æç»“æœ: {len(summary_data['category_results'])} ä¸ªç±»åˆ«")
        
        if 'linear_analysis' in summary_data:
            linear = summary_data['linear_analysis']
            print(f"Linearåˆ†æ: {len(linear.get('linear_projection_stats', {}))} ä¸ªprojection")
        
        # ç¡¬ä»¶ä¿¡æ¯
        if 'hardware_specs' in summary_data:
            hw = summary_data['hardware_specs']
            print(f"\nç¡¬ä»¶ä¿¡æ¯: {hw.get('gpu_name', 'Unknown')} ({hw.get('n_gpu', 1)} GPU)")
            print(f"å³°å€¼è®¡ç®—: {hw.get('phi', 0):.1f} TFLOPs/s")
            print(f"å³°å€¼å¸¦å®½: {hw.get('pi', 0):.1f} GB/s")
        
        # æ•´ä½“æŒ‡æ ‡
        if 'overall_metrics' in summary_data:
            metrics = summary_data['overall_metrics']
            print(f"\næ•´ä½“æ•ˆç‡: {metrics.get('overall_efficiency', 0):.3f}")
            print(f"æ€»è®¡ç®—æ—¶é—´: {metrics.get('total_kernel_time_us', 0)/1000:.1f} ms")
            print(f"æ€»FLOPS: {metrics.get('total_flops', 0)/1e12:.2f} TFLOPs")

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='vLLM OEAç»“æœæ•°æ®æå–å™¨')
    parser.add_argument('--input', required=True, help='è¾“å…¥çš„å®Œæ•´OEA Stage 4ç»“æœæ–‡ä»¶')
    parser.add_argument('--output', help='è¾“å‡ºçš„æ±‡æ€»æ•°æ®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    try:
        # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶åå’Œè·¯å¾„
        if args.output:
            output_file = args.output
        else:
            # ä»è¾“å…¥æ–‡ä»¶åæå–pod_name
            input_basename = os.path.basename(args.input)
            if input_basename.startswith('oea_stage4_') and input_basename.endswith('_processed.json'):
                pod_name = input_basename[len('oea_stage4_'):-len('_processed.json')]
            else:
                pod_name = 'unknown'
            
            # è·å–è¾“å…¥æ–‡ä»¶æ‰€åœ¨ç›®å½•
            input_dir = os.path.dirname(args.input)
            # ç”Ÿæˆè¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼šè¾“å…¥æ–‡ä»¶æ‰€åœ¨æ–‡ä»¶å¤¹/oea_summary_pod_name.json
            output_file = os.path.join(input_dir, f'oea_summary_{pod_name}.json')
        
        extractor = OEASummaryExtractorVLLM()
        success = extractor.extract_from_file(args.input, output_file)
        
        if success:
            print(f"\nâœ… æå–å®Œæˆï¼")
            return 0
        else:
            print(f"\nâŒ æå–å¤±è´¥ï¼")
            return 1
            
    except Exception as e:
        print(f"\nâŒ ç¨‹åºå¼‚å¸¸: {str(e)}")
        import traceback
        traceback.print_exc()
        return 1

if __name__ == "__main__":
    exit(main())