Kernel_Name,Operator_Type,Appears_In_Cases,Total_Execution_Count,Potential_Issues
ampere_fp16_s16816gemm_fp16_128x256_ldg8_f2f_stages_64x3_nn,GEMM,qwen2-ast-sft,64,
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_32x6_nn,GEMM,qwen2-ast-sft,640,
ampere_fp16_s16816gemm_fp16_128x64_ldg8_f2f_stages_64x3_nn,GEMM,qwen2-7b-query,12766,
ampere_fp16_s16816gemm_fp16_256x128_ldg8_f2f_stages_32x3_nn,GEMM,qwen2-ast-sft,32,
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x5_nn,GEMM,qwen2-ast-sft,160,
ampere_fp16_s16816gemm_fp16_64x64_sliced1x2_ldg8_f2f_stages_64x6_nn,GEMM,qwen2-7b-query,6622,
ampere_fp16_s1688gemm_fp16_128x128_ldg8_f2f_stages_32x1_nn,GEMM,qwen2-7b-query,168,
ampere_fp16_s1688gemm_fp16_256x64_ldg8_f2f_stages_32x1_nn,GEMM,qwen2-7b-query,280,
ampere_s16816gemm_fp16_64x64_sliced1x2_ldg8_stages_64x5_tn,GEMM,qwen2-ast-sft,6,
nvjet_hsh_128x128_64x6_1x2_h_bz_NNT,GEMM,recommend-intent,36,
nvjet_hsh_128x136_64x6_4x1_v_bz_NNT,GEMM,recommend-intent,180,
nvjet_hsh_128x152_64x6_4x1_v_bz_NNT,GEMM,recommend-intent,108,
nvjet_hsh_128x168_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,396,
nvjet_hsh_128x176_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,288,
nvjet_hsh_128x184_64x5_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,288,
nvjet_hsh_128x192_64x5_2x1_v_bz_coopB_NNN,GEMM,recommend-intent,144,
nvjet_hsh_128x200_64x5_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,144,
nvjet_hsh_128x208_64x5_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,216,
nvjet_hsh_128x216_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,144,
nvjet_hsh_128x224_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,468,
nvjet_hsh_128x232_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,252,
nvjet_hsh_128x240_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,180,
nvjet_hsh_128x248_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,216,
nvjet_hsh_128x256_64x4_2x1_v_bz_coopA_NNN,GEMM,recommend-intent,432,
nvjet_hsh_128x272_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,252,
nvjet_hsh_128x304_64x3_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,108,
nvjet_hsh_128x80_64x8_1x2_h_bz_NNT,GEMM,recommend-intent,36,
nvjet_hsh_128x8_64x12_4x1_v_bz_NNT,GEMM,recommend-intent,2557,
nvjet_hsh_128x8_64x12_4x1_v_bz_splitK_NNT,GEMM,recommend-intent,2558,
nvjet_hsh_192x104_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,144,
nvjet_hsh_192x128_64x5_2x1_v_bz_coopB_NNT,GEMM,recommend-intent,288,
nvjet_hsh_192x160_64x4_2x1_v_bz_coopB_NNT,GEMM,recommend-intent,36,
nvjet_hsh_192x176_64x4_2x1_v_bz_coopB_NNT,GEMM,recommend-intent,180,
nvjet_hsh_192x192_64x3_2x1_v_bz_coopB_NNN,GEMM,recommend-intent,180,
nvjet_hsh_192x208_64x4_1x2_h_bz_coopB_NNT,GEMM,recommend-intent,36,
nvjet_hsh_192x208_64x4_2x1_v_bz_coopB_NNT,GEMM,recommend-intent,108,
nvjet_hsh_192x88_64x6_2x1_v_bz_NNT,GEMM,recommend-intent,72,
nvjet_hsh_192x96_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,252,
nvjet_hsh_256x104_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,288,
nvjet_hsh_256x104_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,144,
nvjet_hsh_256x112_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,36,
nvjet_hsh_256x112_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,288,
nvjet_hsh_256x120_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,36,
nvjet_hsh_256x120_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,108,
nvjet_hsh_256x128_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,36,
nvjet_hsh_256x128_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,252,
nvjet_hsh_256x136_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,468,
nvjet_hsh_256x136_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,252,
nvjet_hsh_256x144_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,648,
nvjet_hsh_256x144_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,288,
nvjet_hsh_256x152_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,540,
nvjet_hsh_256x152_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,144,
nvjet_hsh_256x160_64x4_1x2_h_bz_coopA_NNT,GEMM,recommend-intent,144,
nvjet_hsh_256x160_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,504,
nvjet_hsh_256x56_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,36,
nvjet_hsh_256x64_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,792,
nvjet_hsh_256x72_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,792,
nvjet_hsh_256x80_64x5_2x1_v_bz_NNT,GEMM,recommend-intent,288,
nvjet_hsh_256x88_64x4_2x1_v_bz_NNT,GEMM,recommend-intent,252,
nvjet_hsh_256x88_64x4_2x1_v_bz_splitK_NNT,GEMM,recommend-intent,72,
nvjet_hsh_256x8_64x6_2x1_v_bz_NNT,GEMM,recommend-intent,2558,
nvjet_hsh_256x8_64x6_2x1_v_bz_splitK_NNT,GEMM,recommend-intent,2558,
nvjet_hsh_256x96_64x4_2x1_v_bz_coopA_NNT,GEMM,recommend-intent,144,
nvjet_hsh_256x96_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,252,
nvjet_hsh_320x128_64x3_2x1_v_bz_coopB_NNT,GEMM,recommend-intent,36,
nvjet_hsh_320x64_64x4_2x1_v_bz_NNT,GEMM,recommend-intent,216,
nvjet_hsh_384x48_64x3_1x1_h_bz_NNT,GEMM,recommend-intent,144,
nvjet_hsh_384x64_64x3_1x1_h_bz_coopB_NNN,GEMM,recommend-intent,288,
nvjet_hsh_384x80_64x3_1x1_h_bz_coopA_NNT,GEMM,recommend-intent,72,
nvjet_hsh_384x96_64x3_1x1_h_bz_coopA_NNT,GEMM,recommend-intent,72,
nvjet_hsh_512x80_64x2_1x1_v_bz_coopA_splitK_NNT,GEMM,recommend-intent,36,
nvjet_hsh_64x128_64x8_2x1_v_bz_NNN,GEMM,recommend-intent,36,
nvjet_hsh_96x128_64x6_2x1_v_bz_splitK_NNN,GEMM,recommend-intent,36,
nvjet_hsh_96x64_64x8_1x2_h_bz_NNN,GEMM,recommend-intent,36,
nvjet_hss_512x8_64x3_2x1_v_bz_TNT,GEMM,recommend-intent,162,
nvjet_tss_512x64_64x2_2x1_v_bz_coopB_TNN,GEMM,qwen3-32b-omega,1,
nvjet_tss_512x72_64x2_2x1_v_bz_coopA_TNT,GEMM,qwen3-32b-omega,107,
nvjet_tst_128x240_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,128,
nvjet_tst_128x248_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,128,
nvjet_tst_128x288_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,128,
nvjet_tst_128x304_64x3_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,128,
nvjet_tst_192x64_64x6_2x1_v_bz_NNT,GEMM,qwen3-32b-omega,128,
nvjet_tst_192x72_64x6_2x1_v_bz_NNT,GEMM,qwen3-32b-omega,11904,
nvjet_tst_256x104_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,448,
nvjet_tst_256x104_64x4_2x1_v_bz_coopA_splitK_NNT,GEMM,qwen3-32b-omega,128,
nvjet_tst_256x112_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,384,
nvjet_tst_256x120_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,192,
nvjet_tst_256x136_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,192,
nvjet_tst_256x144_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,192,
nvjet_tst_256x160_64x4_1x2_h_bz_coopA_NNT,GEMM,qwen3-32b-omega,448,
nvjet_tst_256x160_64x4_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,192,
nvjet_tst_256x72_64x5_4x1_v_bz_splitK_NNT,GEMM,qwen3-32b-omega,11904,
nvjet_tst_384x64_64x3_2x1_v_bz_coopB_NNN,GEMM,qwen3-32b-omega,256,
nvjet_tst_384x80_64x3_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,192,
nvjet_tst_384x88_64x3_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,384,
nvjet_tst_512x72_64x2_2x1_v_bz_coopA_NNT,GEMM,qwen3-32b-omega,384,
nvjet_tst_512x72_64x2_2x1_v_bz_coopA_splitK_NNT,GEMM,qwen3-32b-omega,5952,
nvjet_tst_96x128_64x6_2x1_v_bz_NNN,GEMM,qwen3-32b-omega,576,
nvjet_tst_96x64_64x8_2x1_v_bz_splitK_NNN,GEMM,qwen3-32b-omega,64,
nvjet_tst_96x64_64x8_4x1_v_bz_NNN,GEMM,qwen3-32b-omega,128,
"void cublasLt::splitKreduce_kernel<32, 16, int, float, __half, float, __half, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, __half const*, __half*, float const*, float const*, __half const*, float const*, __half*, void*, long, float*, int*)",GEMM,qwen2-7b-query,700,
"void cublasLt::splitKreduce_kernel<32, 16, int, float, __half, float, false, float, __half, __half, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, __half const*, float*, __half*, float const*, float const*, __half const*, float const*, __half*, void*, long, float*, int*, float*, float const*, float const*, float const*, float const*)",GEMM,recommend-intent,6988,
"void cublasLt::splitKreduce_kernel<32, 16, int, float, __nv_bfloat16, float, false, float, __nv_bfloat16, __nv_bfloat16, true, false, false>(cublasLt::cublasSplitKParams<float>, float const*, __nv_bfloat16 const*, float*, __nv_bfloat16*, float const*, float const*, __nv_bfloat16 const*, float const*, __nv_bfloat16*, void*, long, float*, int*, float*, float const*, float const*, float const*, float const*)",GEMM,qwen3-32b-omega,18048,
void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_f16_128x64_32x6_nn_align2>(cutlass_80_tensorop_f16_s16816gemm_f16_128x64_32x6_nn_align2::Params),GEMM,qwen2-7b-query,112,
void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_f16_256x64_32x4_nn_align2>(cutlass_80_tensorop_f16_s16816gemm_f16_256x64_32x4_nn_align2::Params),GEMM,qwen2-7b-query,13466,
void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_128x128_32x5_nn_align8::Params),GEMM,qwen2-ast-sft,64,包含Activation
void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_256x128_32x3_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_256x128_32x3_nn_align8::Params),GEMM,qwen2-7b-query,336,包含Activation
void cutlass::Kernel2<cutlass_80_tensorop_f16_s16816gemm_relu_f16_256x64_32x4_nn_align8>(cutlass_80_tensorop_f16_s16816gemm_relu_f16_256x64_32x4_nn_align8::Params),GEMM,qwen2-7b-query,56,包含Activation
void cutlass::Kernel2<cutlass_80_tensorop_s16816gemm_f16_64x64_32x6_nn_align8>(cutlass_80_tensorop_s16816gemm_f16_64x64_32x6_nn_align8::Params),GEMM,qwen2-7b-query,700,
void cutlass::Kernel2<cutlass_80_wmma_tensorop_f16_s161616gemm_f16_16x16_128x2_tn_align8>(cutlass_80_wmma_tensorop_f16_s161616gemm_f16_16x16_128x2_tn_align8::Params),GEMM,qwen2-7b-query,247,
fmha_v2_flash_attention_bf16_64_128_S_128_causal_tma_ws_sm90_kernel,Attention,qwen3-32b-omega,704,
fmha_v2_flash_attention_bf16_64_128_S_pagedKV_128_causal_tma_ws_sm90_kernel,Attention,qwen3-32b-omega,192,
fmha_v2_flash_attention_fp16_64_128_S_128_causal_sm80_kernel_nl_tiled,Attention,qwen2-ast-sft,32,
fmha_v2_flash_attention_fp16_64_128_S_128_causal_tma_ws_sm90_kernel,Attention,recommend-intent,3240,
fmha_v2_flash_attention_fp16_64_32_S_128_causal_sm89_kernel_nl,Attention,qwen2-7b-query,168,
"void fastertransformer::add_fusedQKV_bias_transpose_kernel<__half, __half, false, false, (fastertransformer::RopeStyle)1>(__half*, __half*, __half*, fastertransformer::PrefixPromptBatchWeightsParam, __half*, int const*, __half const*, int const*, int const*, int, int, int, int, int, fastertransformer::RopeConfig, bool, bool, bool, bool, bool)",Attention,qwen2-ast-sft,32,Fused操作
"void fastertransformer::add_fusedQKV_bias_transpose_kernel<__half, __half, false, false>(__half*, __half*, __half*, fastertransformer::PrefixPromptBatchWeightsParam, __half*, int const*, __half const*, int const*, int const*, int, int, int, int, int, fastertransformer::RopeConfig, bool)",Attention,qwen2-7b-query,168,Fused操作
"void fastertransformer::masked_multihead_attention_kernel<unsigned short, unsigned short, fastertransformer::KVBlockArray, (unsigned int)128, (unsigned int)256, false, false, false, (unsigned int)16, (unsigned int)16, (unsigned int)4, (unsigned int)8>(fastertransformer::Multihead_attention_params<unsigned short, false>, fastertransformer::KVBlockArray)",Attention,qwen2-7b-query,6902,
"void fastertransformer::masked_multihead_attention_kernel<unsigned short, unsigned short, fastertransformer::KVBlockArray, (unsigned int)128, (unsigned int)512, false, false, true, (fastertransformer::RopeStyle)1, (unsigned int)16, (unsigned int)16, (unsigned int)4, (unsigned int)8>(fastertransformer::Multihead_attention_params<unsigned short, false>, fastertransformer::KVBlockArray)",Attention,qwen2-ast-sft,160,
"void flashinfer::BatchPrefillWithPagedKVCacheKernel<flashinfer::KernelTraits<(flashinfer::MaskMode)1, (unsigned int)16, (unsigned int)1, (unsigned int)2, (unsigned int)8, (unsigned int)8, (unsigned int)1, (unsigned int)4, (flashinfer::PosEncodingMode)0, __nv_bfloat16, __nv_bfloat16, __nv_bfloat16, float, int, flashinfer::DefaultAttention<false, false, false, false> >, flashinfer::BatchPrefillPagedParams<__nv_bfloat16, __nv_bfloat16, __nv_bfloat16, int> >(flashinfer::BatchPrefillPagedParams<__nv_bfloat16, __nv_bfloat16, __nv_bfloat16, int>)",Attention,qwen3-32b-omega,6912,
"void rtp_llm::add_fusedQKV_bias_transpose_kernel<__half, __half, false, false, (rtp_llm::RopeStyle)1>(__half*, __half*, __half*, rtp_llm::PrefixPromptBatchWeightsParam, __half*, void*, int const*, __half const*, int const*, int const*, int, int, int, int, int, rtp_llm::RopeConfig, bool, bool, bool, bool, bool)",Attention,recommend-intent,3240,Fused操作
"void rtp_llm::add_fusedQKV_bias_transpose_kernel<__nv_bfloat16, __nv_bfloat16, false, false, (rtp_llm::RopeStyle)1>(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, rtp_llm::PrefixPromptBatchWeightsParam, __nv_bfloat16*, void*, int const*, __nv_bfloat16 const*, int const*, int const*, int, int, int, int, int, rtp_llm::RopeConfig, bool, bool, bool, bool, bool, bool)",Attention,qwen3-32b-omega,704,Fused操作
"void rtp_llm::add_fusedQKV_bias_transpose_kernel<__nv_bfloat16, __nv_bfloat16, true, true, (rtp_llm::RopeStyle)1>(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, rtp_llm::PrefixPromptBatchWeightsParam, __nv_bfloat16*, void*, int const*, __nv_bfloat16 const*, int const*, int const*, int, int, int, int, int, rtp_llm::RopeConfig, bool, bool, bool, bool, bool, bool)",Attention,qwen3-32b-omega,192,Fused操作
"void rtp_llm::decode_add_fusedQKV_bias_transpose_non_int8_with_rope_cache_kernel<__nv_bfloat16, __nv_bfloat16, (rtp_llm::RopeStyle)1, 4, 4, 4>(__nv_bfloat16*, __nv_bfloat16*, __nv_bfloat16*, rtp_llm::KVBlockArray, __nv_bfloat16*, int const*, __nv_bfloat16 const*, float const*, int, int, int, int, rtp_llm::RopeConfig, bool, bool, bool, bool)",Attention,qwen3-32b-omega,6912,Fused操作
"void rtp_llm::masked_multihead_attention_kernel<unsigned short, unsigned short, rtp_llm::KVBlockArray, (unsigned int)128, (unsigned int)512, false, false, true, (rtp_llm::RopeStyle)1, (unsigned int)16, (unsigned int)16, (unsigned int)4, (unsigned int)8>(rtp_llm::Multihead_attention_params<unsigned short, false>, rtp_llm::KVBlockArray)",Attention,recommend-intent,3242,
"void fastertransformer::generalRmsNorm<__half2, false, false, true, false>(__half2*, __half2*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, float, int, int, float const*, float*, signed char*)",Normalization,"qwen2-7b-query, qwen2-ast-sft",7094,
"void fastertransformer::generalRmsNorm<__half2, false, false, true, true>(__half2*, __half2*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, float, int, int, float const*, float*, signed char*)",Normalization,qwen2-ast-sft,6,
"void fastertransformer::generalRmsNorm<__half2, true, false, true, false>(__half2*, __half2*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, float, int, int, float const*, float*, signed char*)",Normalization,"qwen2-7b-query, qwen2-ast-sft",7093,
"void rtp_llm::fusedQkRmsNorm<__half2, false>(__half2*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, int, int, float, int, int)",Normalization,recommend-intent,5797,Fused操作
"void rtp_llm::fusedQkRmsNorm<__nv_bfloat162, false>(__nv_bfloat162*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, int, int, float, int, int)",Normalization,qwen3-32b-omega,6912,Fused操作
"void rtp_llm::generalRmsNorm<__half2, false, false, true, false, signed char>(__half2*, __half2*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, float, int, int, float const*, float*, signed char*)",Normalization,recommend-intent,5797,
"void rtp_llm::generalRmsNorm<__half2, false, false, true, true, signed char>(__half2*, __half2*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, float, int, int, float const*, float*, signed char*)",Normalization,recommend-intent,162,
"void rtp_llm::generalRmsNorm<__half2, true, false, true, false, signed char>(__half2*, __half2*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, __half2 const*, float, int, int, float const*, float*, signed char*)",Normalization,recommend-intent,5798,
"void rtp_llm::generalRmsNorm<__nv_bfloat162, false, false, true, false, signed char>(__nv_bfloat162*, __nv_bfloat162*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, float, int, int, float const*, float*, signed char*)",Normalization,qwen3-32b-omega,6912,
"void rtp_llm::generalRmsNorm<__nv_bfloat162, false, false, true, true, signed char>(__nv_bfloat162*, __nv_bfloat162*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, float, int, int, float const*, float*, signed char*)",Normalization,qwen3-32b-omega,108,
"void rtp_llm::generalRmsNorm<__nv_bfloat162, true, false, true, false, signed char>(__nv_bfloat162*, __nv_bfloat162*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, float, int, int, float const*, float*, signed char*)",Normalization,qwen3-32b-omega,6912,
"void fastertransformer::addBiasSoftMax<float>(float*, float const*, int const*, bool const*, int, int)",Activation,qwen2-7b-query,247,
"void fastertransformer::generic_activation<fastertransformer::SiluActivation, __half2, __half2>(__half2*, __half2 const*, __half2 const*, __half2 const*, int const*, __half2 const*, int, float const*, float const*, __half2 const*, int const*, int, int, int, int)",Activation,"qwen2-7b-query, qwen2-ast-sft",7093,
"void flashinfer::activation::act_and_mul_kernel<__half, &silu(float const&)>(__half*, __half const*, int)",Activation,recommend-intent,5798,
"void rtp_llm::addBiasSoftMax<float>(float*, float const*, int const*, bool const*, int, int)",Activation,qwen3-32b-omega,108,
"void rtp_llm::generic_activation<rtp_llm::SiluActivation, __nv_bfloat162, __nv_bfloat162>(__nv_bfloat162*, __nv_bfloat162 const*, __nv_bfloat162 const*, __nv_bfloat162 const*, int const*, __nv_bfloat162 const*, int, float const*, float const*, __nv_bfloat162 const*, int const*, int, int, int, int)",Activation,qwen3-32b-omega,6912,
"fastertransformer::computeToppDecay(float*, float const*, int const*, float const*, float const*, int const*, int)",Sampling,qwen2-7b-query,247,
"fastertransformer::curandBatchInitialize(curandStateXORWOW*, int, unsigned long long const*)",Sampling,qwen2-7b-query,32,
"fastertransformer::curandInitialize(curandStateXORWOW*, int, unsigned long long)",Sampling,qwen2-ast-sft,6,
"fastertransformer::set_topp_runtime_args(int, unsigned int, unsigned int*, int, float, float*, int, bool*, float*, float*, float const*, float*, float const*, int*, unsigned int const*)",Sampling,"qwen2-7b-query, qwen2-ast-sft",22,
"fastertransformer::topPInitialize(int*, int*, int*, int, int)",Sampling,qwen2-7b-query,247,
"void at::native::(anonymous namespace)::distribution_elementwise_grid_stride_kernel<float, 4, void at::native::templates::cuda::uniform_and_transform<float, float, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, void at::native::(anonymous namespace)::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_and_transform<float, float, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_and_transform<float, float, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2} const&, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(int, float)#1}>(long, at::PhiloxCudaState, void at::native::templates::cuda::uniform_and_transform<float, float, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, void at::native::(anonymous namespace)::distribution_nullary_kernel<float, float, float4, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_and_transform<float, float, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2}, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_and_transform<float, float, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1}>(at::TensorIteratorBase&, at::CUDAGeneratorImpl*, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(curandStatePhilox4_32_10*)#2} const&, void at::native::templates::cuda::uniform_kernel<at::CUDAGeneratorImpl*>(at::TensorIteratorBase&, double, double, at::CUDAGeneratorImpl*)::{lambda()#1}::operator()() const::{lambda()#2}::operator()() const::{lambda(float)#1})::{lambda(int, float)#1})",Sampling,qwen3-32b-omega,108,
"void cub::CUB_200301_700_750_800_860_890_900_NS::DeviceSegmentedRadixSortKernel<cub::CUB_200301_700_750_800_860_890_900_NS::DeviceRadixSortPolicy<float, int, int>::Policy900, false, true, float, int, int*, int*, int, cub::CUB_200301_700_750_800_860_890_900_NS::detail::identity_decomposer_t>(float const*, float*, int const*, int*, int*, int*, int, int, int, cub::CUB_200301_700_750_800_860_890_900_NS::detail::identity_decomposer_t)",Sampling,qwen2-7b-query,494,
"void cub::CUB_200301_700_750_800_860_890_900_NS::DeviceSegmentedRadixSortKernel<cub::CUB_200301_700_750_800_860_890_900_NS::DeviceRadixSortPolicy<float, int, int>::Policy900, true, true, float, int, int*, int*, int, cub::CUB_200301_700_750_800_860_890_900_NS::detail::identity_decomposer_t>(float const*, float*, int const*, int*, int*, int*, int, int, int, cub::CUB_200301_700_750_800_860_890_900_NS::detail::identity_decomposer_t)",Sampling,qwen2-7b-query,988,
"void fastertransformer::batchApplyMinLengthPenaltyNew<float>(float*, int const*, int const*, int const*, int const*, int)",Sampling,qwen2-ast-sft,5,
"void fastertransformer::batchApplyTemperaturePenalty<float>(float*, float const*, float const*, int, int, int)",Sampling,"qwen2-7b-query, qwen2-ast-sft",253,
"void fastertransformer::setup_topk_runtime_args<(unsigned int)1024>(int, unsigned int, unsigned int*, int, float, float*, int, bool*)",Sampling,"qwen2-7b-query, qwen2-ast-sft",22,
"void fastertransformer::topk_stage1<float, 128, 8>(float const*, float*, int*, float*, bool const*, int, int const*, int, int const*, bool const*)",Sampling,qwen2-ast-sft,6,
"void fastertransformer::topk_stage2_sampling<float, 128, 8, false>(int const*, float*, int*, int*, bool*, float*, float*, float*, int, int const*, float, float const*, curandStateXORWOW*, int const*, int, bool const*)",Sampling,qwen2-ast-sft,6,
"void fastertransformer::topp_beam_topk_kernel<float, 1, 256>(float const*, int*, float*, int, int*, int*, float, float const*, bool const*)",Sampling,qwen2-7b-query,247,
"void fastertransformer::topp_sampling<float, 256>(float*, int*, int*, int*, bool*, float*, float*, int const*, int const*, int, curandStateXORWOW*, float, float const*, int const*, int, bool const*)",Sampling,qwen2-7b-query,247,
"void flashinfer::sampling::TopKTopPSamplingFromProbKernel<(unsigned int)1024, (cub::CUB_200500_700_750_800_860_890_900_NS::BlockScanAlgorithm)2, (cub::CUB_200500_700_750_800_860_890_900_NS::BlockReduceAlgorithm)2, (unsigned int)4, false, float, int>(float*, float*, int*, float*, int*, bool*, int, float, unsigned int, unsigned int)",Sampling,qwen3-32b-omega,108,
"void rtp_llm::batchApplyMinLengthPenaltyNew<float>(float*, int const*, int const*, int const*, int const*, int, int)",Sampling,"qwen3-32b-omega, recommend-intent",270,
"void rtp_llm::batchApplyRepetitionPenalty<float, (rtp_llm::RepetitionPenaltyType)1>(float*, float const*, int const*, int, int, int const*, int, int)",Sampling,recommend-intent,162,
"void rtp_llm::batchApplyTemperaturePenalty<float>(float*, float const*, float const*, int, int, int)",Sampling,qwen3-32b-omega,108,
"void fastertransformer::embedding_lookup_kernel<__half, false, false, false>(__half*, __half const*, double, __half const*, __half const*, int const*, int const*, int const*, int const*, int, long)",Embedding,qwen2-ast-sft,6,
"void rtp_llm::embedding_lookup_kernel<__half, false, false, false>(__half*, __half const*, double, __half const*, __half const*, int const*, int const*, int const*, int const*, int, long)",Embedding,recommend-intent,161,
"void rtp_llm::embedding_lookup_kernel<__nv_bfloat16, false, false, false>(__nv_bfloat16*, __nv_bfloat16 const*, double, __nv_bfloat16 const*, __nv_bfloat16 const*, int const*, int const*, int const*, int const*, int, long)",Embedding,qwen3-32b-omega,108,
"void at::native::(anonymous namespace)::indexSelectLargeIndex<c10::Half, int, unsigned int, 2, 2, -2, true>(at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<int, unsigned int>, int, int, unsigned int, unsigned int, long)",Memory,qwen2-7b-query,6,
"void at::native::(anonymous namespace)::indexSelectSmallIndex<c10::Half, int, unsigned int, 2, 2, -2>(at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<int, unsigned int>, int, int, unsigned int, long)",Memory,qwen2-7b-query,241,
"void at::native::(anonymous namespace)::indexSelectSmallIndex<c10::Half, long, unsigned int, 2, 2, -2>(at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<c10::Half, unsigned int>, at::cuda::detail::TensorInfo<long, unsigned int>, int, int, unsigned int, long)",Memory,qwen2-7b-query,246,
"void at::native::elementwise_kernel<128, 4, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1}>(int, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::DivFunctor<c10::Half> > const&)::{lambda(int)#1})",Memory,qwen2-7b-query,247,
"void at::native::elementwise_kernel<128, 4, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1}>(int, void at::native::gpu_kernel_impl<at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > >(at::TensorIteratorBase&, at::native::BinaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> > const&)::{lambda(int)#1})",Memory,qwen2-7b-query,247,
"void at::native::elementwise_kernel<128, 4, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1}>(int, void at::native::gpu_kernel_impl<at::native::CUDAFunctor_add<c10::Half> >(at::TensorIteratorBase&, at::native::CUDAFunctor_add<c10::Half> const&)::{lambda(int)#1})",Memory,qwen2-7b-query,247,
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4> >(at::native::ReduceOp<c10::Half, at::native::NormTwoOps<c10::Half, float, c10::Half>, unsigned int, c10::Half, 4>)",Memory,qwen2-7b-query,246,
"void at::native::reduce_kernel<512, 1, at::native::ReduceOp<float, at::native::ArgMaxOps<float>, unsigned int, long, 4> >(at::native::ReduceOp<float, at::native::ArgMaxOps<float>, unsigned int, long, 4>)",Memory,recommend-intent,162,
"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#11}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#11}::operator()() const::{lambda(bool)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)",Memory,qwen2-7b-query,247,
"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#2}::operator()() const::{lambda()#7}::operator()() const::{lambda(float)#1}, at::detail::Array<char*, 2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)",Memory,qwen2-7b-query,247,
"void at::native::unrolled_elementwise_kernel<at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#3}::operator()() const::{lambda(int)#1}, std::array<char*, (unsigned long)2>, 4, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1> >(int, at::native::direct_copy_kernel_cuda(at::TensorIteratorBase&)::{lambda()#3}::operator()() const::{lambda()#3}::operator()() const::{lambda(int)#1}, std::array<char*, (unsigned long)2>, TrivialOffsetCalculator<1, unsigned int>, TrivialOffsetCalculator<1, unsigned int>, at::native::memory::LoadWithCast<1>, at::native::memory::StoreWithCast<1>)",Memory,recommend-intent,162,
"void at::native::vectorized_elementwise_kernel<4, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2> >(int, at::native::AUnaryFunctor<c10::Half, c10::Half, c10::Half, at::native::binary_internal::MulFunctor<float> >, at::detail::Array<char*, 2>)",Memory,qwen2-7b-query,247,
"void at::native::vectorized_elementwise_kernel<4, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2> >(int, at::native::CUDAFunctorOnSelf_add<c10::Half>, at::detail::Array<char*, 2>)",Memory,qwen2-7b-query,247,
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<c10::Half>, at::detail::Array<char*, 1>)",Memory,qwen2-7b-query,247,
"void at::native::vectorized_elementwise_kernel<4, at::native::FillFunctor<float>, at::detail::Array<char*, 1> >(int, at::native::FillFunctor<float>, at::detail::Array<char*, 1>)",Memory,qwen2-7b-query,494,
"void fastertransformer::transpose4dBatchMajorKVCache<__half, __half, fastertransformer::KVBlockArray>(__half const*, __half const*, fastertransformer::KVBlockArray, int, int, int, float const*, int const*, int const*)",Memory,qwen2-7b-query,168,
"void fastertransformer::transposeAxis01<int>(int*, int*, int const*, int, int)",Memory,qwen2-ast-sft,12,
"void rtp_llm::transposeAxis01<__nv_bfloat16>(__nv_bfloat16*, __nv_bfloat16*, int, int, int)",Memory,qwen3-32b-omega,108,
"void rtp_llm::transposeAxis01<float>(float*, float*, int, int, int)",Memory,qwen3-32b-omega,108,
"void rtp_llm::transposeAxis01<int>(int*, int*, int const*, int, int)",Memory,"qwen3-32b-omega, recommend-intent",540,
"fastertransformer::ConvertOffsetToAddr(unsigned long*, unsigned long const*, unsigned long const*, int const*, int, int, int, int)",Utility,qwen2-7b-query,247,
"fastertransformer::ConvertOffsetToBlockArrayData(int*, int const*, int, int, int)",Utility,qwen2-ast-sft,192,
"fastertransformer::getCuSeqLensKernel(int*, int const*, int const*, int)",Utility,qwen2-7b-query,6902,
"fastertransformer::getPaddingOffsetAndCuSeqLensKernel(int*, int*, int const*, int, int)",Utility,qwen2-7b-query,6,
"rtp_llm::ConvertOffsetToBlockArrayData(int*, int const*, int, int, int)",Utility,"qwen3-32b-omega, recommend-intent",6604,
"void fastertransformer::addBiasResidual<__half, 1, __half>(__half*, __half const*, __half const*, __half const*, __half const*, float const*, float const*, int, int)",Utility,"qwen2-7b-query, qwen2-ast-sft",7093,
"void rtp_llm::addBiasResidual<__half, 1, __half>(__half*, __half const*, __half const*, __half const*, __half const*, float const*, float const*, int, int)",Utility,recommend-intent,5798,
"void rtp_llm::addBiasResidual<__nv_bfloat16, 1, __nv_bfloat16>(__nv_bfloat16*, __nv_bfloat16 const*, __nv_bfloat16 const*, __nv_bfloat16 const*, __nv_bfloat16 const*, float const*, float const*, int, int)",Utility,qwen3-32b-omega,6912,
"ncclDevKernel_AllGather_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",Communication,qwen3-32b-omega,216,
"ncclDevKernel_AllReduce_Sum_bf16_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",Communication,qwen3-32b-omega,13824,
"ncclDevKernel_Broadcast_RING_LL(ncclDevComm*, unsigned long, ncclWork*)",Communication,qwen3-32b-omega,216,
"void fastertransformer::lookupHiddenStateOfLastToken<__half>(__half*, __half const*, int const*, int, int, int)",Others,qwen2-ast-sft,1,需要人工分类
"void rtp_llm::lookupHiddenStateOfLastToken<__half>(__half*, __half const*, int const*, int, int, int)",Others,recommend-intent,90,需要人工分类
"void rtp_llm::lookupHiddenStateOfLastToken<__nv_bfloat16>(__nv_bfloat16*, __nv_bfloat16 const*, int const*, int, int, int)",Others,qwen3-32b-omega,14,需要人工分类
